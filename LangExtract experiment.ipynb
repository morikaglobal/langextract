{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73PvCX8OKM4I"
      },
      "source": [
        "LangExtract - Google's New Library for NLP Tasks\n",
        "\n",
        "https://www.youtube.com/watch?v=t-53fouKqWI\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "youtube↑の動画のColab note\n",
        "\n",
        "\n",
        "https://colab.research.google.com/drive/1oGBOCdz4XSiY-C9rCsgO1033PEN1uK2s?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9T0HsaGoH3E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DPb_gfl5oHsg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "# import google.generativeai as genai\n",
        "\n",
        "# 環境変数の準備 (左端の鍵アイコンでGOOGLE_API_KEYを設定)\n",
        "# GOOGLE_API_KEY=userdata.get(\"GOOGLE_API_KEY\")\n",
        "# genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YYIExUEatr4z"
      },
      "outputs": [],
      "source": [
        "LANGEXTRACT_API_KEY = userdata.get('LANGEXTRACT_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2p2FJ-ByuLwY"
      },
      "outputs": [],
      "source": [
        "os.environ['LANGEXTRACT_API_KEY'] = LANGEXTRACT_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "27eYlQEMuLsL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fJh3XHh_ot2i",
        "outputId": "ec901f5e-4b22-4c66-f5de-8c5666181d4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langextract\n",
            "  Downloading langextract-1.0.9-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (1.4.0)\n",
            "Requirement already satisfied: aiohttp>=3.8.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (3.13.0)\n",
            "Collecting async_timeout>=4.0.0 (from langextract)\n",
            "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting exceptiongroup>=1.1.0 (from langextract)\n",
            "  Downloading exceptiongroup-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: google-genai>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (1.41.0)\n",
            "Collecting ml-collections>=0.1.0 (from langextract)\n",
            "  Downloading ml_collections-1.1.0-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: more-itertools>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (10.8.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (2.2.2)\n",
            "Requirement already satisfied: pydantic>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (2.11.10)\n",
            "Requirement already satisfied: python-dotenv>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (1.1.1)\n",
            "Requirement already satisfied: PyYAML>=6.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.25.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from langextract) (4.15.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8.0->langextract) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8.0->langextract) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8.0->langextract) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8.0->langextract) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8.0->langextract) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8.0->langextract) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.8.0->langextract) (1.22.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai>=0.1.0->langextract) (4.11.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-genai>=0.1.0->langextract) (2.38.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai>=0.1.0->langextract) (0.28.1)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai>=0.1.0->langextract) (8.5.0)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai>=0.1.0->langextract) (15.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->langextract) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->langextract) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.0->langextract) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.8.0->langextract) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.8.0->langextract) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.8.0->langextract) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.25.0->langextract) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.25.0->langextract) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.25.0->langextract) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.25.0->langextract) (2025.10.5)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai>=0.1.0->langextract) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai>=0.1.0->langextract) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai>=0.1.0->langextract) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai>=0.1.0->langextract) (4.9.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai>=0.1.0->langextract) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai>=0.1.0->langextract) (0.16.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->langextract) (1.17.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai>=0.1.0->langextract) (0.6.1)\n",
            "Downloading langextract-1.0.9-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.2/106.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
            "Downloading exceptiongroup-1.3.0-py3-none-any.whl (16 kB)\n",
            "Downloading ml_collections-1.1.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ml-collections, exceptiongroup, async_timeout, langextract\n",
            "Successfully installed async_timeout-5.0.1 exceptiongroup-1.3.0 langextract-1.0.9 ml-collections-1.1.0\n"
          ]
        }
      ],
      "source": [
        "pip install langextract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HjP3ScWsIbni"
      },
      "outputs": [],
      "source": [
        "import textwrap\n",
        "import langextract as lx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYmXfu2MJ1A-"
      },
      "source": [
        "# Shakespeare example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fBh_o4o0otxq"
      },
      "outputs": [],
      "source": [
        "\n",
        "# prompt = textwrap.dedent(\"\"\"\\\n",
        "# 与えられたテキストから登場人物、感情、関係性を抽出してください。\n",
        "# 文脈と深みを加えるために、すべてのエンティティに意味のある属性を提供してください。\n",
        "# 重要：extraction_textには入力からの正確なテキストを使用してください。言い換えはしないでください。\n",
        "# 重複するテキストスパンがないよう、出現順にエンティティを抽出してください。\n",
        "# 注意：戯曲の台本では、話者名はすべて大文字で表示され、その後にピリオドが続きます。\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LC9hREB2otnt"
      },
      "outputs": [],
      "source": [
        "# examples = [\n",
        "# lx.data.ExampleData(\n",
        "# text=textwrap.dedent(\"\"\"\\\n",
        "# ROMEO. But soft! What light through yonder window breaks?\n",
        "# It is the east, and Juliet is the sun.\n",
        "# JULIET. O Romeo, Romeo! Wherefore art thou Romeo?\"\"\"),\n",
        "# extractions=[\n",
        "# lx.data.Extraction(\n",
        "# extraction_class=\"登場人物\",\n",
        "# extraction_text=\"ROMEO\",\n",
        "# attributes={\"感情状態\": \"驚嘆\"}\n",
        "# ),\n",
        "# lx.data.Extraction(\n",
        "# extraction_class=\"感情\",\n",
        "# extraction_text=\"But soft!\",\n",
        "# attributes={\"感覚\": \"穏やかな畏敬\", \"登場人物\": \"Romeo\"}\n",
        "# ),\n",
        "# lx.data.Extraction(\n",
        "# extraction_class=\"関係性\",\n",
        "# extraction_text=\"Juliet is the sun\",\n",
        "# attributes={\"種類\": \"隠喩\", \"登場人物1\": \"Romeo\", \"登場人物2\": \"Juliet\"}\n",
        "# ),\n",
        "# lx.data.Extraction(\n",
        "# extraction_class=\"登場人物\",\n",
        "# extraction_text=\"JULIET\",\n",
        "# attributes={\"感情状態\": \"憧憬\"}\n",
        "# ),\n",
        "# lx.data.Extraction(\n",
        "# extraction_class=\"感情\",\n",
        "# extraction_text=\"Wherefore art thou Romeo?\",\n",
        "# attributes={\"感覚\": \"切望する問い\", \"登場人物\": \"Juliet\"}\n",
        "# ),\n",
        "# ]\n",
        "# )\n",
        "# ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "gC6q4jddpFkX"
      },
      "outputs": [],
      "source": [
        "# input_text = (\n",
        "# \"Lady Juliet gazed longingly at the stars, her heart aching for Romeo\"\n",
        "# )\n",
        "\n",
        "# result = lx.extract(\n",
        "# text_or_documents=input_text,\n",
        "# prompt_description=prompt,\n",
        "# examples=examples,\n",
        "# model_id=\"gemini-2.5-flash\",\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "H9LBQ-YYpFgQ"
      },
      "outputs": [],
      "source": [
        "# from pprint import pprint\n",
        "# pprint(result.extractions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "XBX9hAaBpFbD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TpFMYmMMpFRe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UG0KJqvo_pd"
      },
      "source": [
        "# Custom example from the youtube video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "w_Sy58unT9ps"
      },
      "outputs": [],
      "source": [
        "TC_ARTICLE = \"\"\"Shortly after Hunter Lightman joined OpenAI as a researcher in 2022, he watched his colleagues launch ChatGPT, one of the fastest-growing products ever. Meanwhile, Lightman quietly worked on a team teaching OpenAI’s models to solve high school math competitions.\n",
        "\n",
        "Today that team, known as MathGen, is considered instrumental to OpenAI’s industry-leading effort to create AI reasoning models: the core technology behind AI agents that can do tasks on a computer like a human would.\n",
        "\n",
        "“We were trying to make the models better at mathematical reasoning, which at the time they weren’t very good at,” Lightman told TechCrunch, describing MathGen’s early work.\n",
        "\n",
        "OpenAI’s models are far from perfect today — the company’s latest AI systems still hallucinate and its agents struggle with complex tasks.\n",
        "\n",
        "But its state-of-the-art models have improved significantly on mathematical reasoning. One of OpenAI’s models recently won a gold medal at the International Math Olympiad, a math competition for the world’s brightest high school students. OpenAI believes these reasoning capabilities will translate to other subjects, and ultimately power general-purpose agents that the company has always dreamed of building.\n",
        "\n",
        "ChatGPT was a happy accident — a lowkey research preview turned viral consumer business — but OpenAI’s agents are the product of a years-long, deliberate effort within the company.\n",
        "\n",
        "“Eventually, you’ll just ask the computer for what you need and it’ll do all of these tasks for you,” said OpenAI CEO Sam Altman at the company’s first developer conference in 2023. “These capabilities are often talked about in the AI field as agents. The upsides of this are going to be tremendous.\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "esAxR4kBKho6"
      },
      "outputs": [],
      "source": [
        "# 1. Define a concise prompt\n",
        "\n",
        "prompt = textwrap.dedent(\"\"\"\\\n",
        "Extract people's name, ai models, products and company names in order of appearance.\n",
        "Use exact text for extractions. Do not paraphrase or overlap entities.\n",
        "Provide meaningful related entities for each entity to add context.\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "YxRjCgcWUA4o"
      },
      "outputs": [],
      "source": [
        "# 2. Provide a high-quality example to guide the model\n",
        "examples = [\n",
        "    lx.data.ExampleData(\n",
        "        text=(\n",
        "            \"David Ha from Sakana AI labs has trained many models\"\n",
        "            \" including the early 'WM1' and his company makes a product called 'AI Scientist' .\"\n",
        "        ),\n",
        "        extractions=[\n",
        "            lx.data.Extraction(\n",
        "                extraction_class=\"person_name\",\n",
        "                extraction_text=\"David Ha\",\n",
        "                attributes={\"company\": \"Sakana AI\"},\n",
        "            ),\n",
        "            lx.data.Extraction(\n",
        "                extraction_class=\"company_name\",\n",
        "                extraction_text=\"Sakana AI\",\n",
        "                attributes={\"employee\": \"David Ha\"},\n",
        "            ),\n",
        "            lx.data.Extraction(\n",
        "                extraction_class=\"ai_model\",\n",
        "                extraction_text=\"WM1\",\n",
        "                attributes={\"company\": \"Sakana AI\"},\n",
        "            ),\n",
        "            lx.data.Extraction(\n",
        "                extraction_class=\"product\",\n",
        "                extraction_text=\"'AI Scientist'\",\n",
        "                attributes={\"company\": \"Sakana AI\"},\n",
        "            ),\n",
        "        ],\n",
        "    )\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "nTbbSjgLJ7YH"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 3. Run the extraction on your input text\n",
        "input_text = (\n",
        "    TC_ARTICLE\n",
        ")\n",
        "result = lx.extract(\n",
        "    text_or_documents=input_text,\n",
        "    prompt_description=prompt,\n",
        "    examples=examples,\n",
        "    model_id=\"gemini-2.5-flash\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsA0qJ1uJ7zW",
        "outputId": "4aee4328-0550-4fa4-e9f9-3750c964db39"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AnnotatedDocument(extractions=[Extraction(extraction_class='person_name', extraction_text='Hunter Lightman', char_interval=CharInterval(start_pos=14, end_pos=29), alignment_status=<AlignmentStatus.MATCH_EXACT: 'match_exact'>, extraction_index=1, group_index=0, description=None, attributes={'company': 'OpenAI'}), Extraction(extraction_class='company_name', extraction_text='OpenAI', char_interval=CharInterval(start_pos=37, end_pos=43), alignment_status=<AlignmentStatus.MATCH_EXACT: 'match_exact'>, extraction_index=2, group_index=1, description=None, attributes={'employee': 'Hunter Lightman'}), Extraction(extraction_class='product', extraction_text='ChatGPT', char_interval=CharInterval(start_pos=102, end_pos=109), alignment_status=<AlignmentStatus.MATCH_EXACT: 'match_exact'>, extraction_index=3, group_index=2, description=None, attributes={'company': 'OpenAI'}), Extraction(extraction_class='company_name', extraction_text='MathGen', char_interval=CharInterval(start_pos=290, end_pos=297), alignment_status=<AlignmentStatus.MATCH_EXACT: 'match_exact'>, extraction_index=4, group_index=3, description=None, attributes={'employee': 'Lightman'}), Extraction(extraction_class='company_name', extraction_text='TechCrunch', char_interval=CharInterval(start_pos=612, end_pos=622), alignment_status=<AlignmentStatus.MATCH_EXACT: 'match_exact'>, extraction_index=5, group_index=4, description=None, attributes=None), Extraction(extraction_class='company_name', extraction_text='OpenAI', char_interval=CharInterval(start_pos=892, end_pos=898), alignment_status=<AlignmentStatus.MATCH_EXACT: 'match_exact'>, extraction_index=1, group_index=0, description=None, attributes=None), Extraction(extraction_class='ai_model', extraction_text='ChatGPT', char_interval=CharInterval(start_pos=1210, end_pos=1217), alignment_status=<AlignmentStatus.MATCH_FUZZY: 'match_fuzzy'>, extraction_index=2, group_index=1, description=None, attributes={'company': 'OpenAI'}), Extraction(extraction_class='company_name', extraction_text='OpenAI', char_interval=CharInterval(start_pos=1037, end_pos=1043), alignment_status=<AlignmentStatus.MATCH_EXACT: 'match_exact'>, extraction_index=3, group_index=2, description=None, attributes={'employee': 'Sam Altman'}), Extraction(extraction_class='person_name', extraction_text='Sam Altman', char_interval=CharInterval(start_pos=1510, end_pos=1520), alignment_status=<AlignmentStatus.MATCH_EXACT: 'match_exact'>, extraction_index=4, group_index=3, description=None, attributes={'company': 'OpenAI'})], text='Shortly after Hunter Lightman joined OpenAI as a researcher in 2022, he watched his colleagues launch ChatGPT, one of the fastest-growing products ever. Meanwhile, Lightman quietly worked on a team teaching OpenAI’s models to solve high school math competitions.\\n\\nToday that team, known as MathGen, is considered instrumental to OpenAI’s industry-leading effort to create AI reasoning models: the core technology behind AI agents that can do tasks on a computer like a human would.\\n\\n“We were trying to make the models better at mathematical reasoning, which at the time they weren’t very good at,” Lightman told TechCrunch, describing MathGen’s early work.\\n\\nOpenAI’s models are far from perfect today — the company’s latest AI systems still hallucinate and its agents struggle with complex tasks.\\n\\nBut its state-of-the-art models have improved significantly on mathematical reasoning. One of OpenAI’s models recently won a gold medal at the International Math Olympiad, a math competition for the world’s brightest high school students. OpenAI believes these reasoning capabilities will translate to other subjects, and ultimately power general-purpose agents that the company has always dreamed of building.\\n\\nChatGPT was a happy accident — a lowkey research preview turned viral consumer business — but OpenAI’s agents are the product of a years-long, deliberate effort within the company.\\n\\n“Eventually, you’ll just ask the computer for what you need and it’ll do all of these tasks for you,” said OpenAI CEO Sam Altman at the company’s first developer conference in 2023. “These capabilities are often talked about in the AI field as agents. The upsides of this are going to be tremendous.')"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrf5T8VeJ771"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whLDWVpwYg_y"
      },
      "source": [
        "### Print out the people mentioned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIyOvfC7UA9j",
        "outputId": "909c55e7-c68e-4fcd-9ce4-cabc88eef566"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "person_name\n",
            "Hunter Lightman\n",
            "{'company': 'OpenAI'}\n",
            "CharInterval(start_pos=14, end_pos=29)\n",
            "====================\n",
            "person_name\n",
            "Sam Altman\n",
            "{'company': 'OpenAI'}\n",
            "CharInterval(start_pos=1510, end_pos=1520)\n",
            "====================\n"
          ]
        }
      ],
      "source": [
        "for ex in result.extractions:\n",
        "    if ex.extraction_class == \"person_name\":\n",
        "        print(ex.extraction_class)\n",
        "        print(ex.extraction_text)\n",
        "        print(ex.attributes)\n",
        "        print(ex.char_interval)\n",
        "        print(\"====================\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxxHLMuYnLKR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQO5s_ZGZB81"
      },
      "source": [
        "## Companies mentioned\n",
        "\n",
        "since company names are repeated,\n",
        "\n",
        "\n",
        "print(unique_companies)\n",
        "\n",
        "in the end only gives the list of company names that are mentioned at least once"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTIXbo22oo3p"
      },
      "source": [
        "unique_companies = set()\n",
        "\n",
        "\n",
        "【Python】set型（集合型）とは\n",
        "\n",
        "https://aiacademy.jp/media/?p=2945\n",
        "\n",
        "set型の特徴として、リスト型と非常に似ているデータ型ですが、重複した値を格納できない点や、添え字やキーなどの概念がなく、ユニークな要素である点、要素の順序を保持しない点などの特徴があります。\n",
        "\n",
        "set型は波括弧{}で要素を囲むと定義出来ます。\n",
        "\n",
        "この時重複する値は取り除かれるため、一意な値のみが要素として残る事を注意しておきましょう。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKhNs--gpDBl",
        "outputId": "46672cfa-bad8-476d-8d31-ca0a686eb199"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'set'>\n",
            "{10, 20, 50, 30}\n"
          ]
        }
      ],
      "source": [
        "s = {10, 20, 30, 50, 50}   # not a list, this is a set as not [] but {}\n",
        "print(type(s))\n",
        "print(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-6EuJv1WqPh",
        "outputId": "c39ca70f-1c23-433a-cbd3-ec91b823081a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI\n",
            "CharInterval(start_pos=37, end_pos=43)\n",
            "====================\n",
            "MathGen\n",
            "CharInterval(start_pos=290, end_pos=297)\n",
            "====================\n",
            "TechCrunch\n",
            "CharInterval(start_pos=612, end_pos=622)\n",
            "====================\n",
            "OpenAI\n",
            "CharInterval(start_pos=892, end_pos=898)\n",
            "====================\n",
            "OpenAI\n",
            "CharInterval(start_pos=1037, end_pos=1043)\n",
            "====================\n",
            "{'MathGen', 'TechCrunch', 'OpenAI'}\n"
          ]
        }
      ],
      "source": [
        "unique_companies = set()\n",
        "\n",
        "for ex in result.extractions:\n",
        "    if ex.extraction_class == \"company_name\":\n",
        "        unique_companies.add(ex.extraction_text)\n",
        "\n",
        "for ex in result.extractions:\n",
        "    if ex.extraction_class == \"company_name\":\n",
        "        print(ex.extraction_text)\n",
        "        print(ex.char_interval)\n",
        "        print(\"====================\")\n",
        "\n",
        "print(unique_companies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvA5-RTnnLNE",
        "outputId": "f0b02d83-e2ba-4f45-8fca-5c573ac4d5d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "product\n",
            "ChatGPT\n",
            "====================\n",
            "ai_model\n",
            "ChatGPT\n",
            "====================\n"
          ]
        }
      ],
      "source": [
        "for ex in result.extractions:\n",
        "    if ex.extraction_class == \"ai_model\" or ex.extraction_class == \"product\":\n",
        "        print(ex.extraction_class)\n",
        "        print(ex.extraction_text)\n",
        "        # print(ex.char_interval)\n",
        "        print(\"====================\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIzNAO_JnOpa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KM8Yu1PknOtE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CemlFfkhnOww"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
